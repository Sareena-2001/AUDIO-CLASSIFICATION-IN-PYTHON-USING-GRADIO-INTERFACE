{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Define the model pipeline for audio classification\n",
        "model_id = \"sanchit-gandhi/distilhubert-finetuned-gtzan\"\n",
        "pipe = pipeline(\"audio-classification\", model=model_id)\n",
        "\n",
        "def classify_audio(filepath):\n",
        "    if filepath is None:\n",
        "        return \"No file provided\"\n",
        "\n",
        "    if not os.path.isfile(filepath):\n",
        "        return f\"File does not exist: {filepath}\"\n",
        "\n",
        "    try:\n",
        "        print(f\"Classifying file: {filepath}\")\n",
        "\n",
        "        # Read the audio file from the filepath\n",
        "        audio, sample_rate = sf.read(filepath)\n",
        "\n",
        "        # Convert to mono if the audio has multiple channels\n",
        "        if len(audio.shape) > 1:\n",
        "            audio = np.mean(audio, axis=1)\n",
        "\n",
        "        # Ensure the audio is in the correct format\n",
        "        audio = np.array(audio)\n",
        "\n",
        "        # Classify the audio\n",
        "        preds = pipe(audio)\n",
        "\n",
        "        if preds:\n",
        "            # Find the prediction with the highest confidence\n",
        "            best_pred = max(preds, key=lambda x: x[\"score\"])\n",
        "            return best_pred[\"label\"]\n",
        "        else:\n",
        "            return \"No predictions\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error during classification: {e}\")\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Gradio interface with custom styling\n",
        "demo = gr.Interface(\n",
        "    fn=classify_audio,\n",
        "    inputs=gr.Audio(type=\"filepath\"),\n",
        "    outputs=gr.Label(),\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        background-color: #FADADD;  /* Baby pink color */\n",
        "    }\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(debug=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "S4sQGWBtCpT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "8e008ab4-1c68-40f6-9d1d-b5a081afc58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://9899b0ad0a8de442cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9899b0ad0a8de442cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying file: /tmp/gradio/4ec6ae3b224ba3b3b1f47f4f364542184aad9446384d1325642277439d10b127/mixkit-praise-the-lord-262.wav\n"
          ]
        }
      ]
    }
  ]
}